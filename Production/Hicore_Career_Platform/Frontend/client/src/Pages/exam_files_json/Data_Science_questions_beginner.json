[
  {
    "id": 5,
    "topic": "Big Data Storage Technologies",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which technology is commonly used for storing large amounts of unstructured data in big data environments?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Data lakes"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Relational databases"
      },
      {
        "label": "C",
        "type": "text",
        "value": "USB flash drives"
      },
      {
        "label": "D",
        "type": "text",
        "value": "DVDs"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Data lakes are designed to store vast amounts of unstructured data, making them ideal for big data environments."
      }
    ]
  },
  {
    "id": 6,
    "topic": "Probability Distributions",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following distributions is used for binary data?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Normal distribution"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Binomial distribution"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Poisson distribution"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Chi-squared distribution"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "The binomial distribution is used for binary data where there are exactly two possible outcomes in a series of experiments."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Data Manipulation Libraries",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is not a Python library commonly used for data manipulation?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Pandas"
      },
      {
        "label": "B",
        "type": "text",
        "value": "NumPy"
      },
      {
        "label": "C",
        "type": "text",
        "value": "TensorFlow"
      },
      {
        "label": "D",
        "type": "text",
        "value": "SciPy"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "TensorFlow is primarily used for machine learning and neural network computations, not for general data manipulation tasks like Pandas, NumPy, and SciPy."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Basic Concepts of Data Visualization",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the primary purpose of data visualization?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "To confuse the audience with complex representations"
      },
      {
        "label": "B",
        "type": "text",
        "value": "To communicate information clearly and efficiently"
      },
      {
        "label": "C",
        "type": "text",
        "value": "To display data without interpretation"
      },
      {
        "label": "D",
        "type": "text",
        "value": "To increase data processing time"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Data visualization aims to communicate information clearly and efficiently, making complex data more accessible and understandable."
      }
    ]
  },
  {
    "id": 10,
    "topic": "Big Data Technologies",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which technology is primarily used for distributed storage and processing of big data?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Hadoop"
      },
      {
        "label": "B",
        "type": "text",
        "value": "MySQL"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Excel"
      },
      {
        "label": "D",
        "type": "text",
        "value": "JavaScript"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Hadoop is widely recognized for its capabilities in distributed storage and processing of large data sets (big data) using the MapReduce programming model."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Basic Concepts of Data Visualization",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the primary purpose of data visualization?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "To create visually appealing abstract art"
      },
      {
        "label": "B",
        "type": "text",
        "value": "To communicate information clearly and effectively through graphical means"
      },
      {
        "label": "C",
        "type": "text",
        "value": "To confuse the viewer with complex representations"
      },
      {
        "label": "D",
        "type": "text",
        "value": "To replace all textual data with images"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Data visualization is used to communicate information clearly and effectively through graphical representations, making it easier for viewers to understand and analyze data."
      }
    ]
  },
  {
    "id": 7,
    "topic": "Big Data Characteristics",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT a characteristic of big data?"
      },
      {
        "type": "formula",
        "value": ""
      },
      {
        "type": "image",
        "value": ""
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Velocity"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Volume"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Variety"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Vulnerability"
      }
    ],
    "correct": "D",
    "explanation": [
      {
        "type": "text",
        "value": "The three main characteristics of big data are Volume, Velocity, and Variety. Vulnerability is not considered a core characteristic of big data."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Python Libraries for Data Manipulation",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT a Python library commonly used for data manipulation?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Pandas"
      },
      {
        "label": "B",
        "type": "text",
        "value": "NumPy"
      },
      {
        "label": "C",
        "type": "text",
        "value": "TensorFlow"
      },
      {
        "label": "D",
        "type": "text",
        "value": "SciPy"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "TensorFlow is primarily a library for machine learning and not specifically for data manipulation."
      }
    ]
  },
  {
    "id": 4,
    "topic": "Big Data Technologies",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which technology is primarily used to process large volumes of data in real-time?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "SQL databases"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Excel spreadsheets"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Hadoop"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Apache Kafka"
      }
    ],
    "correct": "D",
    "explanation": [
      {
        "type": "text",
        "value": "Apache Kafka is a framework implemented by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Foundational Concepts",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT typically considered a core component of data science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Machine Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data Visualization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Quantum Computing"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Statistics"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Quantum Computing, while a significant field in computing, is not typically considered a core component of data science, which focuses more on Machine Learning, Data Visualization, and Statistics."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Descriptive Statistics",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What measure of central tendency is most affected by extreme values in the data set?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Mean"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Median"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Mode"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Range"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "The mean is the average of all data points and is significantly influenced by extreme values, either very high or very low, compared to the median and mode."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Descriptive Statistics",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the median of the following set of numbers: 3, 7, 9, 5, 11?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "7"
      },
      {
        "label": "B",
        "type": "text",
        "value": "9"
      },
      {
        "label": "C",
        "type": "text",
        "value": "5"
      },
      {
        "label": "D",
        "type": "text",
        "value": "11"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "After arranging the numbers in ascending order (3, 5, 7, 9, 11), the median is the middle value, which is 7."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Python Data Manipulation Libraries",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which Python library is primarily used for data manipulation and is known for its ease of use for beginners?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Pandas"
      },
      {
        "label": "B",
        "type": "text",
        "value": "NumPy"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Matplotlib"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Scipy"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Pandas is the most widely used Python library for data manipulation, especially suitable for beginners due to its high-level data structures and easy-to-use functions."
      }
    ]
  },
  {
    "id": 2,
    "topic": "Comparing Data Visualization Types",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which type of data visualization is primarily used for displaying distributions of data over a range?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Line chart"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Histogram"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Pie chart"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Network diagram"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Histograms are used to show distributions of variables and are helpful in showing where values are concentrated over an interval."
      }
    ]
  },
  {
    "id": 7,
    "topic": "Foundational Concepts",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT typically considered a key component of data science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Statistics"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data Visualization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Classical Literature"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Machine Learning"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Classical Literature is not a component of data science, which typically includes statistics, data visualization, and machine learning."
      }
    ]
  },
  {
    "id": 10,
    "topic": "Model Evaluation",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "In the context of machine learning, what does the term 'overfitting' refer to?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "A model's inability to generalize from the training data to unseen data"
      },
      {
        "label": "B",
        "type": "text",
        "value": "A model that is too simple, both underfitting the training and test data"
      },
      {
        "label": "C",
        "type": "text",
        "value": "When the training process has not yet reached convergence"
      },
      {
        "label": "D",
        "type": "text",
        "value": "A model appropriately fitting the training data and generalizing to new data"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Overfitting occurs when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data."
      }
    ]
  },
  {
    "id": 6,
    "topic": "Features of Pandas",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the primary use of the Pandas library in Python?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Web development"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data manipulation and analysis"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Machine learning"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Game development"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Pandas is widely used for data manipulation and analysis. It offers data structures and operations for manipulating numerical tables and time series."
      }
    ]
  },
  {
    "id": 4,
    "topic": "Basic Concepts of Machine Learning",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the term used to describe the dataset used to provide an unbiased evaluation of a model fit on the training dataset while tuning model hyperparameters?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Training Set"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Testing Set"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Validation Set"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Data Set"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "The validation set is used to evaluate a model's performance during the tuning of hyperparameters, providing an unbiased evaluation."
      }
    ]
  },
  {
    "id": 7,
    "topic": "Descriptive Statistics",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What does the mean represent in a data set?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "The middle value of the data set"
      },
      {
        "label": "B",
        "type": "text",
        "value": "The most frequently occurring value in the data set"
      },
      {
        "label": "C",
        "type": "text",
        "value": "The average value of the data set"
      },
      {
        "label": "D",
        "type": "text",
        "value": "The difference between the highest and lowest values in the data set"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "The mean is calculated by summing all the values in the data set and then dividing by the number of values, representing the average value."
      }
    ]
  },
  {
    "id": 8,
    "topic": "Comparison of Visualization Techniques",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which type of visualization is typically used to display the distribution of data over a continuous interval?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Pie chart"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Histogram"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Line graph"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Network diagram"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "A histogram is used to represent the distribution of numerical data over a continuous interval, showing the frequencies of data points in successive ranges."
      }
    ]
  },
  {
    "id": 10,
    "topic": "Basic Operations in Pandas",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What function in Pandas is used to read a CSV file into a DataFrame?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "read_csv()"
      },
      {
        "label": "B",
        "type": "text",
        "value": "to_csv()"
      },
      {
        "label": "C",
        "type": "text",
        "value": "csv_reader()"
      },
      {
        "label": "D",
        "type": "text",
        "value": "read_file()"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "The function read_csv() in Pandas is used to import data from a CSV file into a DataFrame."
      }
    ]
  },
  {
    "id": 2,
    "topic": "Introduction to Data Science",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Who is recognized for coining the term 'Data Science'?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "William S. Cleveland"
      },
      {
        "label": "B",
        "type": "text",
        "value": "D.J. Patil"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Jeff Hammerbacher"
      },
      {
        "label": "D",
        "type": "text",
        "value": "John Tukey"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "William S. Cleveland is credited with coining the term 'Data Science' and advocating for an expansion of statistics beyond theory into technical computing."
      }
    ]
  },
  {
    "id": 8,
    "topic": "Big Data Technologies",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which technology is primarily used for distributed storage and processing of big data?"
      },
      {
        "type": "formula",
        "value": ""
      },
      {
        "type": "image",
        "value": ""
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Hadoop"
      },
      {
        "label": "B",
        "type": "text",
        "value": "MySQL"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Excel"
      },
      {
        "label": "D",
        "type": "text",
        "value": "PowerPoint"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Hadoop is widely known for its capabilities in distributed storage and processing of large data sets. MySQL, Excel, and PowerPoint do not offer the same capabilities for handling big data."
      }
    ]
  },
  {
    "id": 9,
    "topic": "Foundational Concepts of Data Science",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT commonly considered a key component of data science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Machine Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data Visualization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Literature Review"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Statistics"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Literature Review is not typically considered a key component of data science, which more commonly includes Machine Learning, Data Visualization, and Statistics."
      }
    ]
  },
  {
    "id": 9,
    "topic": "Basic Concepts",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the primary purpose of data visualization?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "To confuse the audience with complex representations"
      },
      {
        "label": "B",
        "type": "text",
        "value": "To communicate information clearly and efficiently"
      },
      {
        "label": "C",
        "type": "text",
        "value": "To display data without interpretation"
      },
      {
        "label": "D",
        "type": "text",
        "value": "To increase the data processing time"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Data visualization aims to communicate information clearly and efficiently through graphical representations, making complex data more accessible and understandable."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Basic Concepts of Data Visualization",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What is the primary purpose of data visualization?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "To confuse the audience with complex data."
      },
      {
        "label": "B",
        "type": "text",
        "value": "To create aesthetically pleasing abstract art."
      },
      {
        "label": "C",
        "type": "text",
        "value": "To communicate information clearly and efficiently."
      },
      {
        "label": "D",
        "type": "text",
        "value": "To encrypt sensitive information."
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Data visualization aims to communicate information clearly and efficiently via graphical representations, making complex data more accessible."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Types of Machine Learning",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which type of machine learning is primarily concerned with labeling data into predefined categories?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Supervised Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Unsupervised Learning"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Reinforcement Learning"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Semi-supervised Learning"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Supervised learning involves training a model on a labeled dataset, meaning each training example is paired with an input and a corresponding output label."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Big Data Characteristics",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which characteristic of big data deals with the rate at which data is received and processed?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Velocity"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Volume"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Variety"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Veracity"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Velocity refers to the speed at which data flows in from sources like business processes, machines, networks, and human interaction with things like social media sites, mobile devices, etc."
      }
    ]
  },
  {
    "id": 6,
    "topic": "Introduction to Data Science",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "What does reproducible research in data science imply?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Research that can be duplicated by others using the same data and methods"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Research that has been peer-reviewed"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Research that results in the same findings regardless of the data used"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Research that can be published in scientific journals"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Reproducible research implies that the research can be duplicated by others using the same data and methods, ensuring the findings are reliable and verifiable."
      }
    ]
  },
  {
    "id": 10,
    "topic": "Chart Types",
    "difficulty": "easy",
    "question": [
      {
        "type": "text",
        "value": "Which type of chart is typically used to display continuous data over time?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Pie chart"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Bar chart"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Line chart"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Histogram"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Line charts are ideal for displaying continuous data over time, helping to visualize trends and changes."
      }
    ]
  },
  {
    "id": 7,
    "topic": "Types of Machine Learning",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which type of machine learning is primarily used when the algorithm must decide from a specific set of outcomes based on the input data?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Unsupervised Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Supervised Learning"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Reinforcement Learning"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Semi-supervised Learning"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Supervised Learning is used when the model is trained on a labeled dataset, which means the model learns to predict the output from the input data."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Hypothesis Testing",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "In a hypothesis test, if the p-value is 0.03 and the significance level is 0.05, what is the appropriate action regarding the null hypothesis?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Reject the null hypothesis"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Accept the null hypothesis"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Increase the sample size to decrease the p-value"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Report no significant finding"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Since the p-value (0.03) is less than the significance level (0.05), the null hypothesis is rejected, indicating significant evidence against the null hypothesis."
      }
    ]
  },
  {
    "id": 6,
    "topic": "History and Evolution of Data Science",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which year is often cited as the beginning of the modern Data Science movement, marked by the publication '50 years of Data Science'?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "1997"
      },
      {
        "label": "B",
        "type": "text",
        "value": "2001"
      },
      {
        "label": "C",
        "type": "text",
        "value": "2017"
      },
      {
        "label": "D",
        "type": "text",
        "value": "2010"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "The year 2017 is often noted as a significant year in data science, marked by David Donoho's publication '50 years of Data Science'."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Data Science Components",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT typically considered a core component of data science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Machine Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data Visualization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Blockchain"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Statistics"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Blockchain is not typically considered a core component of data science, which usually includes machine learning, data visualization, and statistics."
      }
    ]
  },
  {
    "id": 9,
    "topic": "Foundational Concepts of Data Science",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is NOT typically considered a core component of data science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Machine Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data Visualization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Quantum Computing"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Statistics"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Quantum Computing is not typically considered a core component of data science. Core components usually include Statistics, Machine Learning, and Data Visualization."
      }
    ]
  },
  {
    "id": 9,
    "topic": "Types of Machine Learning",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which type of machine learning is primarily concerned with labeling new observations based on examples of labeled data provided during training?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Supervised Learning"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Unsupervised Learning"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Reinforcement Learning"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Semi-supervised Learning"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Supervised learning uses a training set of labeled data to learn a function that can be used to predict the output associated with new inputs."
      }
    ]
  },
  {
    "id": 4,
    "topic": "Machine Learning Algorithms",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which algorithm is best suited for finding groups of similar instances in a dataset without prior knowledge of the group definitions?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "K-Means Clustering"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Linear Regression"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Logistic Regression"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Decision Trees"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "K-Means Clustering is an unsupervised learning algorithm that is used to group data into k number of clusters by finding centroids in a dataset with no prior labeling information."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Data Manipulation with Pandas",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which method in Pandas is used primarily for deleting any rows with missing data in a DataFrame?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "fillna()"
      },
      {
        "label": "B",
        "type": "text",
        "value": "dropna()"
      },
      {
        "label": "C",
        "type": "text",
        "value": "isnull()"
      },
      {
        "label": "D",
        "type": "text",
        "value": "notna()"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "The dropna() method in Pandas is used to remove missing values (NaN). fillna() fills the missing values, isnull() checks for missing values, and notna() checks for non-missing values."
      }
    ]
  },
  {
    "id": 6,
    "topic": "Real-time Data Processing",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "Which big data technology is best suited for real-time data processing and analytics?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Hadoop"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Apache Spark"
      },
      {
        "label": "C",
        "type": "text",
        "value": "MySQL"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Microsoft Excel"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Apache Spark is renowned for its ability to process real-time data efficiently, thanks to its in-memory computing capabilities."
      }
    ]
  },
  {
    "id": 2,
    "topic": "Regression Analysis",
    "difficulty": "medium",
    "question": [
      {
        "type": "text",
        "value": "In the context of multiple linear regression, what does the term 'multicollinearity' refer to?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "A condition where the variance of the error terms is constant"
      },
      {
        "label": "B",
        "type": "text",
        "value": "A condition where the error terms are correlated with each other"
      },
      {
        "label": "C",
        "type": "text",
        "value": "A condition where two or more predictor variables are closely correlated"
      },
      {
        "label": "D",
        "type": "text",
        "value": "A condition where the residuals are perfectly homoscedastic"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Multicollinearity refers to a situation in multiple regression wherein two or more predictor variables are highly correlated, potentially leading to unreliable and unstable estimates of regression coefficients."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Evolution of Data Science",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Which of the following best describes the historical development of data science as a formal discipline?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Data science originated solely from statistics with minimal contributions from computer science."
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data science is a new field that emerged in the 21st century without any historical precedents."
      },
      {
        "label": "C",
        "type": "text",
        "value": "Data science evolved through the convergence of statistics, computer science, and domain-specific knowledge."
      },
      {
        "label": "D",
        "type": "text",
        "value": "Data science has remained unchanged since its inception and has not been influenced by technological advancements."
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Data science has grown as an interdisciplinary field, incorporating elements of statistics, computer science, and specific knowledge from various domains, which reflects its comprehensive and evolving nature."
      }
    ]
  },
  {
    "id": 2,
    "topic": "Binomial Distribution",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "A biased coin is flipped 10 times. The probability of getting a head in a single flip is 0.2. What is the probability of getting exactly 2 heads in 10 flips?"
      },
      {
        "type": "formula",
        "value": "P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "formula",
        "value": "0.3020"
      },
      {
        "label": "B",
        "type": "formula",
        "value": "0.3758"
      },
      {
        "label": "C",
        "type": "formula",
        "value": "0.2013"
      },
      {
        "label": "D",
        "type": "formula",
        "value": "0.1209"
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Using the binomial formula P(X = 2) = \\binom{10}{2} (0.2)^2 (0.8)^8 = 45 * 0.04 * 0.16777216 = 0.3020. Hence, the probability of getting exactly 2 heads in 10 flips is 0.3020."
      }
    ]
  },
  {
    "id": 7,
    "topic": "Data Manipulation Performance",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "When handling a large DataFrame in Pandas, which method is generally more memory efficient for applying a transformation to multiple columns simultaneously?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Using the .apply() method with a lambda function"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Using vectorized operations directly on DataFrame columns"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Using a for loop to iterate over each row and apply changes"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Using the .merge() method to combine modified columns"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Vectorized operations in Pandas are implemented via highly optimized pandas library code and are much faster and more memory efficient compared to using .apply() with a lambda function, which can be slower and consume more memory with large DataFrames."
      }
    ]
  },
  {
    "id": 4,
    "topic": "Complex Data Filtering with NumPy",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "If you have a NumPy array 'arr' and you need to retrieve elements that are either greater than 10 or less than 2, which function would accomplish this?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "arr[(arr > 10) & (arr < 2)]"
      },
      {
        "label": "B",
        "type": "text",
        "value": "arr[(arr > 10) | (arr < 2)]"
      },
      {
        "label": "C",
        "type": "text",
        "value": "arr[np.where((arr > 10) | (arr < 2))]"
      },
      {
        "label": "D",
        "type": "text",
        "value": "arr.max(10).min(2)"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Option B is correct because it uses the logical OR operator '|', which correctly gathers elements either greater than 10 or less than 2. This is the appropriate method for combining two different conditional criteria in NumPy."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Histograms vs. Bar Charts",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Which of the following is a key difference between histograms and bar charts in data visualization?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Histograms display categorical data, whereas bar charts display numerical data distributions."
      },
      {
        "label": "B",
        "type": "text",
        "value": "Histograms are used to show distributions of variables, whereas bar charts compare variables."
      },
      {
        "label": "C",
        "type": "text",
        "value": "Bar charts use vertical lines at each data point, unlike histograms."
      },
      {
        "label": "D",
        "type": "text",
        "value": "Bar charts require a zero-baseline, but histograms do not."
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Histograms are specifically used for showing the frequency distribution of quantitative data, whereas bar charts are used to compare different categories of data."
      }
    ]
  },
  {
    "id": 5,
    "topic": "Advanced Data Manipulation",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Considering a DataFrame 'df' with a DateTime index and a column 'A', which line of code will resample the data to provide the mean value of 'A' for the beginning of each month?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "df.resample('M').mean()"
      },
      {
        "label": "B",
        "type": "text",
        "value": "df.resample('MS').mean()"
      },
      {
        "label": "C",
        "type": "text",
        "value": "df.groupby('M').mean()"
      },
      {
        "label": "D",
        "type": "text",
        "value": "df.groupby('MS').mean()"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "The 'MS' string is the correct frequency string to resample the data at the start ('S') of each month ('M'). The 'mean()' function then computes the mean of 'A' for each resulting period."
      }
    ]
  },
  {
    "id": 3,
    "topic": "Conditional Probability",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Given two events A and B in a probability space, where P(A) = 0.5, P(B) = 0.4, and P(A \u2229 B) = 0.2, what is P(A|B)?"
      },
      {
        "type": "formula",
        "value": "P(A|B) = \\frac{P(A \\cap B)}{P(B)}"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "formula",
        "value": "0.5"
      },
      {
        "label": "B",
        "type": "formula",
        "value": "0.4"
      },
      {
        "label": "C",
        "type": "formula",
        "value": "0.2"
      },
      {
        "label": "D",
        "type": "formula",
        "value": "0.5"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "Using the formula for conditional probability, P(A|B) = P(A \u2229 B) / P(B) = 0.2 / 0.4 = 0.5."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Regularization Techniques",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "In the context of preventing overfitting in machine learning models, which regularization technique can be described as adding the sum of the absolute values of coefficients to the loss function of the model?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "L1 regularization"
      },
      {
        "label": "B",
        "type": "text",
        "value": "L2 regularization"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Dropout"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Early stopping"
      }
    ],
    "correct": "A",
    "explanation": [
      {
        "type": "text",
        "value": "L1 regularization, also known as Lasso regression, adds the sum of the absolute values of the coefficients as a penalty term to the loss function. This can lead to sparsity in the model coefficients as some coefficients can become zero."
      }
    ]
  },
  {
    "id": 1,
    "topic": "Reproducible Research",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Which of the following best describes the components necessary for conducting reproducible research in Data Science?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Source code, random seed, and proprietary data"
      },
      {
        "label": "B",
        "type": "text",
        "value": "Source code, version control systems, and open-source datasets"
      },
      {
        "label": "C",
        "type": "text",
        "value": "Source code only"
      },
      {
        "label": "D",
        "type": "text",
        "value": "Data visualization tools, source code, and random seed"
      }
    ],
    "correct": "B",
    "explanation": [
      {
        "type": "text",
        "value": "Reproducible research in Data Science requires the sharing of source code, use of version control systems, and open-source datasets to ensure others can replicate the results."
      }
    ]
  },
  {
    "id": 2,
    "topic": "Evolution of Data Science",
    "difficulty": "hard",
    "question": [
      {
        "type": "text",
        "value": "Considering the historical development and contemporary applications, which of the following statements accurately reflects the impact of data science on modern industries?"
      }
    ],
    "options": [
      {
        "label": "A",
        "type": "text",
        "value": "Data science has had minimal impact on the healthcare industry."
      },
      {
        "label": "B",
        "type": "text",
        "value": "Data science is primarily used in the technology sector, with little application elsewhere."
      },
      {
        "label": "C",
        "type": "text",
        "value": "Data science has revolutionized decision-making processes across various sectors, including healthcare, finance, and retail."
      },
      {
        "label": "D",
        "type": "text",
        "value": "The applications of data science are limited to machine learning and artificial intelligence."
      }
    ],
    "correct": "C",
    "explanation": [
      {
        "type": "text",
        "value": "Data science has broadly impacted multiple sectors by enhancing decision-making processes with data-driven insights, significantly evident in industries like healthcare, finance, and retail."
      }
    ]
  }
]